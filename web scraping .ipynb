{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6e79c0",
   "metadata": {},
   "source": [
    "# project:2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d5ff2",
   "metadata": {},
   "source": [
    "#1)Write a python program to display all the header tags from wikipedia.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb717a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"central-textlogo-wrapper\">\n",
      "<span class=\"central-textlogo__image sprite svg-Wikipedia_wordmark\">\n",
      "Wikipedia\n",
      "</span>\n",
      "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"portal.slogan\">The Free Encyclopedia</strong>\n",
      "</h1>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "10 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get('https://www.wikipedia.org/')\n",
    "#print(response)\n",
    "bs = BeautifulSoup(response.content,'lxml')\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print(\"\")\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407d367f",
   "metadata": {},
   "source": [
    "a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42b4440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team_name: New Zealand\n",
      "Team_Point: 2,051\n",
      "Team_match: 16\n",
      "Team_Ratings: 128\n",
      "\n",
      "Team_name: England\n",
      "Team_Point: 3,226\n",
      "Team_match: 27\n",
      "Team_Ratings: 119\n",
      "\n",
      "Team_name: India\n",
      "Team_Point: 3,085\n",
      "Team_match: 28\n",
      "Team_Ratings: 110\n",
      "\n",
      "Team_name: Pakistan\n",
      "Team_Point: 2,005\n",
      "Team_match: 19\n",
      "Team_Ratings: 106\n",
      "\n",
      "Team_name: Australia\n",
      "Team_Point: 2,325\n",
      "Team_match: 23\n",
      "Team_Ratings: 101\n",
      "\n",
      "Team_name: South Africa\n",
      "Team_Point: 2,111\n",
      "Team_match: 21\n",
      "Team_Ratings: 101\n",
      "\n",
      "Team_name: Bangladesh\n",
      "Team_Point: 2,639\n",
      "Team_match: 27\n",
      "Team_Ratings: 98\n",
      "\n",
      "Team_name: Sri Lanka\n",
      "Team_Point: 2,658\n",
      "Team_match: 29\n",
      "Team_Ratings: 92\n",
      "\n",
      "Team_name: West Indies\n",
      "Team_Point: 2,621\n",
      "Team_match: 38\n",
      "Team_Ratings: 69\n",
      "\n",
      "Team_name: Afghanistan\n",
      "Team_Point: 1,238\n",
      "Team_match: 18\n",
      "Team_Ratings: 69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content)\n",
    "soup1= BeautifulSoup(response.content)\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('tr',class_=\"rankings-block__banner\")\n",
    "Teams=soup.find_all('tr',class_='table-body')[:9]\n",
    "#print(Teams)\n",
    "Team=soup.find('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team=soup1.find('tr',class_='rankings-block__banner')\n",
    "for Team1 in Team_:\n",
    "    Team_name=Team1.find(\"span\",class_=\"u-hide-phablet\").text\n",
    "    Team_match= Team1.find(\"td\",class_='rankings-block__banner--matches').text\n",
    "    Team_Point= Team1.find(\"td\",class_='rankings-block__banner--points').text\n",
    "    Team_Ratings= Team1.find(\"td\",class_='rankings-block__banner--rating u-text-right').text.replace(\" \",\"\").replace(\"\\n\",\"\")\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Point:\",Team_Point)\n",
    "    print(\"Team_match:\",Team_match)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "    \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    \n",
    "    Team_name=Team.find(\"span\",class_=\"u-hide-phablet\").text\n",
    "    Team_matches= Team.find_all(\"td\",class_='table-body__cell u-center-text')\n",
    "    Team_match=Team_matches[0].text\n",
    "    Team_Points= Team.find_all(\"td\",class_='table-body__cell u-center-text')\n",
    "    Team_Point=Team_Points[1].text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Point:\",Team_Point)\n",
    "    print(\"Team_match:\",Team_match)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133ddd3",
   "metadata": {},
   "source": [
    "Top 10 ODI Batsmen along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0687ad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batsmen_name: Babar Azam\n",
      "Team_name: PAK\n",
      "Team_Ratings: 892\n",
      "\n",
      "Batsmen_name: Imam-ul-Haq\n",
      "Team_name: PAK\n",
      "Team_Ratings: 815\n",
      "\n",
      "Batsmen_name: Rassie van der Dussen\n",
      "Team_name: SA\n",
      "Team_Ratings: 789\n",
      "\n",
      "Batsmen_name: Quinton de Kock\n",
      "Team_name: SA\n",
      "Team_Ratings: 784\n",
      "\n",
      "Batsmen_name: Virat Kohli\n",
      "Team_name: IND\n",
      "Team_Ratings: 767\n",
      "\n",
      "Batsmen_name: Rohit Sharma\n",
      "Team_name: IND\n",
      "Team_Ratings: 763\n",
      "\n",
      "Batsmen_name: Ross Taylor\n",
      "Team_name: NZ\n",
      "Team_Ratings: 744\n",
      "\n",
      "Batsmen_name: David Warner\n",
      "Team_name: AUS\n",
      "Team_Ratings: 737\n",
      "\n",
      "Batsmen_name: Jonny Bairstow\n",
      "Team_name: ENG\n",
      "Team_Ratings: 732\n",
      "\n",
      "Batsmen_name: Aaron Finch\n",
      "Team_name: AUS\n",
      "Team_Ratings: 715\n",
      "\n",
      "Player_name: Imam-ul-Haq\n",
      "Team_name: PAK\n",
      "Team_Ratings: 815\n",
      "\n",
      "Player_name: Rassie van der Dussen\n",
      "Team_name: SA\n",
      "Team_Ratings: 789\n",
      "\n",
      "Player_name: Quinton de Kock\n",
      "Team_name: SA\n",
      "Team_Ratings: 784\n",
      "\n",
      "Player_name: Virat Kohli\n",
      "Team_name: IND\n",
      "Team_Ratings: 767\n",
      "\n",
      "Player_name: Rohit Sharma\n",
      "Team_name: IND\n",
      "Team_Ratings: 763\n",
      "\n",
      "Player_name: Ross Taylor\n",
      "Team_name: NZ\n",
      "Team_Ratings: 744\n",
      "\n",
      "Player_name: David Warner\n",
      "Team_name: AUS\n",
      "Team_Ratings: 737\n",
      "\n",
      "Player_name: Jonny Bairstow\n",
      "Team_name: ENG\n",
      "Team_Ratings: 732\n",
      "\n",
      "Player_name: Aaron Finch\n",
      "Team_name: AUS\n",
      "Team_Ratings: 715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup1= BeautifulSoup(response.content,'html.parser')\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('div',class_=\"rankings-block__banner\")[:1]\n",
    "Teams=soup.find_all('tr',class_=\"table-body\")[:9]\n",
    "#print(Team_)\n",
    "Team=soup.find('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team1=soup1.find('div',class_=\"rankings-block__banner\")\n",
    "for Team1 in Team_:\n",
    "    Batsmen_name=Team1.find(\"div\",class_=\"rankings-block__banner--name\").text\n",
    "    \n",
    "    Team_name= Team1.find(\"div\",class_='rankings-block__banner--nationality').text.split()[0]\n",
    "   \n",
    "    Team_Ratings= Team1.find(\"div\",class_='rankings-block__banner--rating').text\n",
    "    print(\"Batsmen_name:\",Batsmen_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    Batsmen_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Batsmen_name:\",Batsmen_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    Player_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Player_name:\",Player_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a94be7",
   "metadata": {},
   "source": [
    "c)Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca8648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowler_name: Trent Boult\n",
      "Team_name: NZ\n",
      "Team_Ratings: 697\n",
      "\n",
      "Bowler_name: Jasprit Bumrah\n",
      "Team_name: IND\n",
      "Team_Ratings: 682\n",
      "\n",
      "Bowler_name: Shaheen Afridi\n",
      "Team_name: PAK\n",
      "Team_Ratings: 681\n",
      "\n",
      "Bowler_name: Josh Hazlewood\n",
      "Team_name: AUS\n",
      "Team_Ratings: 679\n",
      "\n",
      "Bowler_name: Mujeeb Ur Rahman\n",
      "Team_name: AFG\n",
      "Team_Ratings: 676\n",
      "\n",
      "Bowler_name: Mehedi Hasan\n",
      "Team_name: BAN\n",
      "Team_Ratings: 672\n",
      "\n",
      "Bowler_name: Matt Henry\n",
      "Team_name: NZ\n",
      "Team_Ratings: 663\n",
      "\n",
      "Bowler_name: Mohammad Nabi\n",
      "Team_name: AFG\n",
      "Team_Ratings: 657\n",
      "\n",
      "Bowler_name: Rashid Khan\n",
      "Team_name: AFG\n",
      "Team_Ratings: 651\n",
      "\n",
      "Bowler_name: Chris Woakes\n",
      "Team_name: ENG\n",
      "Team_Ratings: 640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup1= BeautifulSoup(response.content,'html.parser')\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('div',class_=\"rankings-block__banner\")[1:2]\n",
    "Teams=soup.find_all('tr',class_='table-body')[9:18]\n",
    "\n",
    "#print(Team_)\n",
    "#print(Teams)\n",
    "Team=soup.find_all('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team1=soup1.find('div',class_=\"rankings-block__banner\")\n",
    "for Team1 in Team_:\n",
    "    Bowler_name=Team1.find(\"div\",class_=\"rankings-block__banner--name\").text\n",
    " \n",
    "    Team_name= Team1.find(\"div\",class_=\"rankings-block__banner--nationality\").text.split()[0]\n",
    "    Team_Ratings= Team1.find(\"div\",class_='rankings-block__banner--rating').text\n",
    "    print(\"Bowler_name:\",Bowler_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    Bowler_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Bowler_name:\",Bowler_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3b744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42479b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12338b8",
   "metadata": {},
   "source": [
    "4)Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bb5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : Shri Ram Nath Kovind (birth - 1945)\n",
      "Term of Office: 25 July, 2017 to 25 July, 2022 \n",
      "Name : Shri Pranab Mukherjee (1935-2020)\n",
      "Term of Office: 25 July, 2012 to 25 July, 2017 \n",
      "Name : Smt Pratibha Devisingh Patil (birth - 1934)\n",
      "Term of Office: 25 July, 2007 to 25 July, 2012 \n",
      "Name : DR. A.P.J. Abdul Kalam (1931-2015)\n",
      "Term of Office: 25 July, 2002 to 25 July, 2007 \n",
      "Name : Shri K. R. Narayanan (1920 - 2005)\n",
      "Term of Office: 25 July, 1997 to 25 July, 2002 \n",
      "Name : Dr Shankar Dayal Sharma (1918-1999)\n",
      "Term of Office: 25 July, 1992 to 25 July, 1997 \n",
      "Name : Shri R Venkataraman (1910-2009)\n",
      "Term of Office: 25 July, 1987 to 25 July, 1992 \n",
      "Name : Giani Zail Singh (1916-1994)\n",
      "Term of Office: 25 July, 1982 to 25 July, 1987 \n",
      "Name : Shri Neelam Sanjiva Reddy (1913-1996)\n",
      "Term of Office: 25 July, 1977 to 25 July, 1982 \n",
      "Name : Dr. Fakhruddin Ali Ahmed (1905-1977)\n",
      "Term of Office: 24 August, 1974 to 11 February, 1977\n",
      "Name : Shri Varahagiri Venkata Giri (1894-1980)\n",
      "Term of Office: 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974\n",
      "Name : Dr. Zakir Husain (1897-1969)\n",
      "Term of Office: 13 May, 1967 to 3 May, 1969\n",
      "Name : Dr. Sarvepalli Radhakrishnan (1888-1975)\n",
      "Term of Office: 13 May, 1962 to 13 May, 1967\n",
      "Name : Dr. Rajendra Prasad (1884-1963) \n",
      "Term of Office: 26 January, 1950 to 13 May, 1962\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "r=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\",'lxml')\n",
    "soup=BeautifulSoup(r.content)\n",
    "president_name=soup.find_all('div',class_=\"presidentListing\")\n",
    "\n",
    "\n",
    "for president in president_name:\n",
    "    President=president.h3.text\n",
    "    term=president.p.text\n",
    "\n",
    "    print(\"Name :\",President)\n",
    "    print(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d6e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f33b7183",
   "metadata": {},
   "source": [
    "a)Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebeef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team_name: Australia\n",
      "Team_Point: 4,837\n",
      "Team_match: 29\n",
      "Team_Ratings: 167\n",
      "\n",
      "Team_name: England\n",
      "Team_Point: 4,046\n",
      "Team_match: 33\n",
      "Team_Ratings: 123\n",
      "\n",
      "Team_name: South Africa\n",
      "Team_Point: 4,157\n",
      "Team_match: 35\n",
      "Team_Ratings: 119\n",
      "\n",
      "Team_name: India\n",
      "Team_Point: 3,219\n",
      "Team_match: 32\n",
      "Team_Ratings: 101\n",
      "\n",
      "Team_name: New Zealand\n",
      "Team_Point: 3,019\n",
      "Team_match: 31\n",
      "Team_Ratings: 97\n",
      "\n",
      "Team_name: West Indies\n",
      "Team_Point: 2,768\n",
      "Team_match: 30\n",
      "Team_Ratings: 92\n",
      "\n",
      "Team_name: Bangladesh\n",
      "Team_Point: 930\n",
      "Team_match: 12\n",
      "Team_Ratings: 78\n",
      "\n",
      "Team_name: Pakistan\n",
      "Team_Point: 1,962\n",
      "Team_match: 30\n",
      "Team_Ratings: 65\n",
      "\n",
      "Team_name: Sri Lanka\n",
      "Team_Point: 495\n",
      "Team_match: 11\n",
      "Team_Ratings: 45\n",
      "\n",
      "Team_name: Ireland\n",
      "Team_Point: 351\n",
      "Team_match: 8\n",
      "Team_Ratings: 44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content)\n",
    "soup1= BeautifulSoup(response.content)\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('tr',class_=\"rankings-block__banner\")\n",
    "Teams=soup.find_all('tr',class_='table-body')[:9]\n",
    "#print(Teams)\n",
    "Team=soup.find('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team=soup1.find('tr',class_='rankings-block__banner')\n",
    "for Team1 in Team_:\n",
    "    Team_name=Team1.find(\"span\",class_=\"u-hide-phablet\").text\n",
    "    Team_match= Team1.find(\"td\",class_='rankings-block__banner--matches').text\n",
    "    Team_Point= Team1.find(\"td\",class_='rankings-block__banner--points').text\n",
    "    Team_Ratings= Team1.find(\"td\",class_='rankings-block__banner--rating u-text-right').text.replace(\" \",\"\").replace(\"\\n\",\"\")\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Point:\",Team_Point)\n",
    "    print(\"Team_match:\",Team_match)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "    \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    \n",
    "    Team_name=Team.find(\"span\",class_=\"u-hide-phablet\").text\n",
    "    Team_matches= Team.find_all(\"td\",class_='table-body__cell u-center-text')\n",
    "    Team_match=Team_matches[0].text\n",
    "    Team_Points= Team.find_all(\"td\",class_='table-body__cell u-center-text')\n",
    "    Team_Point=Team_Points[1].text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Point:\",Team_Point)\n",
    "    print(\"Team_match:\",Team_match)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd18eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97511148",
   "metadata": {},
   "source": [
    "b)Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c29584cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batsmen_name: Alyssa Healy\n",
      "Team_name: AUS\n",
      "Team_Ratings: 785\n",
      "\n",
      "Batsmen_name: Beth Mooney\n",
      "Team_name: AUS\n",
      "Team_Ratings: 749\n",
      "\n",
      "Batsmen_name: Natalie Sciver\n",
      "Team_name: ENG\n",
      "Team_Ratings: 747\n",
      "\n",
      "Batsmen_name: Laura Wolvaardt\n",
      "Team_name: SA\n",
      "Team_Ratings: 732\n",
      "\n",
      "Batsmen_name: Meg Lanning\n",
      "Team_name: AUS\n",
      "Team_Ratings: 710\n",
      "\n",
      "Batsmen_name: Rachael Haynes\n",
      "Team_name: AUS\n",
      "Team_Ratings: 701\n",
      "\n",
      "Batsmen_name: Amy Satterthwaite\n",
      "Team_name: NZ\n",
      "Team_Ratings: 681\n",
      "\n",
      "Batsmen_name: Tammy Beaumont\n",
      "Team_name: ENG\n",
      "Team_Ratings: 667\n",
      "\n",
      "Batsmen_name: Chamari Athapaththu\n",
      "Team_name: SL\n",
      "Team_Ratings: 655\n",
      "\n",
      "Batsmen_name: Smriti Mandhana\n",
      "Team_name: IND\n",
      "Team_Ratings: 649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup1= BeautifulSoup(response.content,'html.parser')\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('div',class_=\"rankings-block__banner\")[:1]\n",
    "Teams=soup.find_all(\"tr\",class_=\"table-body\")[:9]\n",
    "#print(Team_)\n",
    "#print(Teams)\n",
    "Team=soup.find(\"tr\",class_=\"table-body\")\n",
    "#print(Team)\n",
    "Team1=soup1.find('div',class_=\"rankings-block__banner\")\n",
    "#print(Team1)\n",
    "for Team1 in Team_:\n",
    "    Batsmen_name=Team1.find(\"div\",class_='rankings-block__banner--name').text\n",
    "    \n",
    "    Team_name= Team1.find(\"div\",'rankings-block__banner--nationality').text.split()[0]\n",
    "   \n",
    "    Team_Ratings= Team1.find(\"div\",class_='rankings-block__banner--rating').text\n",
    "    print(\"Batsmen_name:\",Batsmen_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    Batsmen_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Batsmen_name:\",Batsmen_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ae1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa9908e7",
   "metadata": {},
   "source": [
    "Top 10 women’s ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32aac003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bowler_name: Sophie Ecclestone\n",
      "Team_name: ENG\n",
      "Team_Ratings: 761\n",
      "\n",
      "Bowler_name: Jess Jonassen\n",
      "Team_name: AUS\n",
      "Team_Ratings: 725\n",
      "\n",
      "Bowler_name: Megan Schutt\n",
      "Team_name: AUS\n",
      "Team_Ratings: 722\n",
      "\n",
      "Bowler_name: Shabnim Ismail\n",
      "Team_name: SA\n",
      "Team_Ratings: 722\n",
      "\n",
      "Bowler_name: Jhulan Goswami\n",
      "Team_name: IND\n",
      "Team_Ratings: 644\n",
      "\n",
      "Bowler_name: Ayabonga Khaka\n",
      "Team_name: SA\n",
      "Team_Ratings: 634\n",
      "\n",
      "Bowler_name: Rajeshwari Gayakwad\n",
      "Team_name: IND\n",
      "Team_Ratings: 613\n",
      "\n",
      "Bowler_name: Hayley Matthews\n",
      "Team_name: WI\n",
      "Team_Ratings: 612\n",
      "\n",
      "Bowler_name: Katherine Brunt\n",
      "Team_name: ENG\n",
      "Team_Ratings: 601\n",
      "\n",
      "Bowler_name: Marizanne Kapp\n",
      "Team_name: SA\n",
      "Team_Ratings: 598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup1= BeautifulSoup(response.content,'html.parser')\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('div',class_=\"rankings-block__banner\")[1:2]\n",
    "Teams=soup.find_all('tr',class_='table-body')[9:18]\n",
    "\n",
    "#print(Team_)\n",
    "#print(Teams)\n",
    "Team=soup.find_all('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team1=soup1.find('div',class_=\"rankings-block__banner\")\n",
    "for Team1 in Team_:\n",
    "    Bowler_name=Team1.find(\"div\",class_=\"rankings-block__banner--name\").text\n",
    " \n",
    "    Team_name= Team1.find(\"div\",class_=\"rankings-block__banner--nationality\").text.split()[0]\n",
    "    Team_Ratings= Team1.find(\"div\",class_='rankings-block__banner--rating').text\n",
    "    print(\"Bowler_name:\",Bowler_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    Bowler_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"Bowler_name:\",Bowler_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e9006",
   "metadata": {},
   "source": [
    "Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6b966c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_rounder_name: Natalie Sciver\n",
      "Team_name: ENG\n",
      "Team_Ratings: 379\n",
      "\n",
      "All_rounder_name: Ellyse Perry\n",
      "Team_name: AUS\n",
      "Team_Ratings: 374\n",
      "\n",
      "All_rounder_name: Marizanne Kapp\n",
      "Team_name: SA\n",
      "Team_Ratings: 349\n",
      "\n",
      "All_rounder_name: Hayley Matthews\n",
      "Team_name: WI\n",
      "Team_Ratings: 339\n",
      "\n",
      "All_rounder_name: Amelia Kerr\n",
      "Team_name: NZ\n",
      "Team_Ratings: 336\n",
      "\n",
      "All_rounder_name: Ashleigh Gardner\n",
      "Team_name: AUS\n",
      "Team_Ratings: 270\n",
      "\n",
      "All_rounder_name: Deepti Sharma\n",
      "Team_name: IND\n",
      "Team_Ratings: 252\n",
      "\n",
      "All_rounder_name: Jess Jonassen\n",
      "Team_name: AUS\n",
      "Team_Ratings: 246\n",
      "\n",
      "All_rounder_name: Katherine Brunt\n",
      "Team_name: ENG\n",
      "Team_Ratings: 220\n",
      "\n",
      "All_rounder_name: Stafanie Taylor\n",
      "Team_name: WI\n",
      "Team_Ratings: 207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "#print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "soup1= BeautifulSoup(response.content,'html.parser')\n",
    "#print(soup)\n",
    "Team_=soup1.find_all('div',class_=\"rankings-block__banner\")[2:3]\n",
    "Teams=soup.find_all('tr',class_='table-body')[18:27]\n",
    "\n",
    "#print(Team_)\n",
    "#print(Teams)\n",
    "Team=soup.find_all('tr',class_='table-body')\n",
    "#print(Team)\n",
    "Team1=soup1.find('div',class_=\"rankings-block__banner\")\n",
    "for Team1 in Team_:\n",
    "    All_rounder_name=Team1.find(\"div\",class_=\"rankings-block__banner--name\").text\n",
    " \n",
    "    Team_name= Team1.find(\"div\",class_=\"rankings-block__banner--nationality\").text.split()[0]\n",
    "    Team_Ratings= Team1.find(\"div\",class_='rankings-block__banner--rating').text\n",
    "    print(\"All_rounder_name:\",All_rounder_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "for Team in Teams:\n",
    "    \n",
    "    All_rounder_name=Team.find(\"td\",class_=\"table-body__cell name\").a.text\n",
    "    Team_name= Team.find(\"span\",class_='table-body__logo-text').text\n",
    "    Team_Ratings= Team.find(\"td\",class_='table-body__cell u-text-right rating').text\n",
    "    print(\"All_rounder_name:\",All_rounder_name)\n",
    "    print(\"Team_name:\",Team_name)\n",
    "    print(\"Team_Ratings:\",Team_Ratings)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50c4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33031d0f",
   "metadata": {},
   "source": [
    "Write a python program to scrape the details of most downloaded articles from AI in last 90 days. https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab641bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper_Title :  Reward is enough\n",
      "Authors:  Silver, David, Singh, Satinder, Precup, Doina, Sutton, Richard S. \n",
      "Published_date :  October 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000862\n",
      "\n",
      "Paper_Title :  Making sense of raw input\n",
      "Authors:  Evans, Richard, Bošnjak, Matko and 5 more\n",
      "Published_date :  October 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000722\n",
      "\n",
      "Paper_Title :  Law and logic: A review from an argumentation perspective\n",
      "Authors:  Prakken, Henry, Sartor, Giovanni \n",
      "Published_date :  October 2015\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370215000910\n",
      "\n",
      "Paper_Title :  Creativity and artificial intelligence\n",
      "Authors:  Boden, Margaret A. \n",
      "Published_date :  August 1998\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370298000551\n",
      "\n",
      "Paper_Title :  Artificial cognition for social human–robot interaction: An implementation\n",
      "Authors:  Lemaignan, Séverin, Warnier, Mathieu and 3 more\n",
      "Published_date :  June 2017\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370216300790\n",
      "\n",
      "Paper_Title :  Explanation in artificial intelligence: Insights from the social sciences\n",
      "Authors:  Miller, Tim \n",
      "Published_date :  February 2019\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370218305988\n",
      "\n",
      "Paper_Title :  Making sense of sensory input\n",
      "Authors:  Evans, Richard, Hernández-Orallo, José and 3 more\n",
      "Published_date :  April 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370220301855\n",
      "\n",
      "Paper_Title :  Conflict-based search for optimal multi-agent pathfinding\n",
      "Authors:  Sharon, Guni, Stern, Roni, Felner, Ariel, Sturtevant, Nathan R. \n",
      "Published_date :  February 2015\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370214001386\n",
      "\n",
      "Paper_Title :  Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning\n",
      "Authors:  Sutton, Richard S., Precup, Doina, Singh, Satinder \n",
      "Published_date :  August 1999\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370299000521\n",
      "\n",
      "Paper_Title :  The Hanabi challenge: A new frontier for AI research\n",
      "Authors:  Bard, Nolan, Foerster, Jakob N. and 13 more\n",
      "Published_date :  March 2020\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370219300116\n",
      "\n",
      "Paper_Title :  Evaluating XAI: A comparison of rule-based and example-based explanations\n",
      "Authors:  van der Waa, Jasper, Nieuwburg, Elisabeth, Cremers, Anita, Neerincx, Mark \n",
      "Published_date :  February 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370220301533\n",
      "\n",
      "Paper_Title :  Argumentation in artificial intelligence\n",
      "Authors:  Bench-Capon, T.J.M., Dunne, Paul E. \n",
      "Published_date :  October 2007\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370207000793\n",
      "\n",
      "Paper_Title :  Algorithms for computing strategies in two-player simultaneous move games\n",
      "Authors:  Bošanský, Branislav, Lisý, Viliam and 3 more\n",
      "Published_date :  August 2016\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370216300285\n",
      "\n",
      "Paper_Title :  Multiple object tracking: A literature review\n",
      "Authors:  Luo, Wenhan, Xing, Junliang and 4 more\n",
      "Published_date :  April 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370220301958\n",
      "\n",
      "Paper_Title :  Selection of relevant features and examples in machine learning\n",
      "Authors:  Blum, Avrim L., Langley, Pat \n",
      "Published_date :  December 1997\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370297000635\n",
      "\n",
      "Paper_Title :  A survey of inverse reinforcement learning: Challenges, methods and progress\n",
      "Authors:  Arora, Saurabh, Doshi, Prashant \n",
      "Published_date :  August 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000515\n",
      "\n",
      "Paper_Title :  Explaining individual predictions when features are dependent: More accurate approximations to Shapley values\n",
      "Authors:  Aas, Kjersti, Jullum, Martin, Løland, Anders \n",
      "Published_date :  September 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000539\n",
      "\n",
      "Paper_Title :  A review of possible effects of cognitive biases on interpretation of rule-based machine learning models\n",
      "Authors:  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Johannes \n",
      "Published_date :  June 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000096\n",
      "\n",
      "Paper_Title :  Integrating social power into the decision-making of cognitive agents\n",
      "Authors:  Pereira, Gonçalo, Prada, Rui, Santos, Pedro A. \n",
      "Published_date :  December 2016\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370216300868\n",
      "\n",
      "Paper_Title :  “That's (not) the output I expected!” On the role of end user expectations in creating explanations of AI systems\n",
      "Authors:  Riveiro, Maria, Thill, Serge \n",
      "Published_date :  September 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000588\n",
      "\n",
      "Paper_Title :  Explaining black-box classifiers using post-hoc explanations-by-example: The effect of explanations and error-rates in XAI user studies\n",
      "Authors:  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, Keane, Mark T. \n",
      "Published_date :  May 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000102\n",
      "\n",
      "Paper_Title :  Algorithm runtime prediction: Methods & evaluation\n",
      "Authors:  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyton-Brown, Kevin \n",
      "Published_date :  January 2014\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370213001082\n",
      "\n",
      "Paper_Title :  Wrappers for feature subset selection\n",
      "Authors:  Kohavi, Ron, John, George H. \n",
      "Published_date :  December 1997\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S000437029700043X\n",
      "\n",
      "Paper_Title :  Commonsense visual sensemaking for autonomous driving – On generalised neurosymbolic online abduction integrating vision and semantics\n",
      "Authors:  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srikrishna \n",
      "Published_date :  October 2021\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370221000734\n",
      "\n",
      "Paper_Title :  Quantum computation, quantum theory and AI\n",
      "Authors:  Ying, Mingsheng \n",
      "Published_date :  February 2010\n",
      "Paper_URL : https://www.sciencedirect.com/science/article/pii/S0004370209001398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "response=requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "Article=soup.find_all(\"li\",class_=\"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\")\n",
    "paper=soup.find(\"li\",class_=\"sc-9zxyh7-1 sc-9zxyh7-2 exAXfr jQmQZp\")\n",
    "\n",
    "for paper in Article:\n",
    "    Paper_Title = paper.find(\"h2\",class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\").text\n",
    "    Authors=paper.find('span',class_=\"sc-1w3fpd7-0 pgLAT\").text\n",
    "    Published_date=paper.find('span',class_=\"sc-1thf9ly-2 bKddwo\").text\n",
    "    Paper_URL=paper.article.a['href']\n",
    "    print(\"Paper_Title : \",Paper_Title )\n",
    "    print(\"Authors: \",Authors)\n",
    "    print('Published_date : ',Published_date)\n",
    "    print(\"Paper_URL :\", Paper_URL)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb1d273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80496eae",
   "metadata": {},
   "source": [
    "7)Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4f934c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline :  Elon Musk challenges Twitter CEO Parag Agrawal to a debate on bots\n",
      "Time:  8 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/elon-musk-challenges-twitter-ceo-parag-agrawal-to-a-debate-on-bots.html\n",
      "\n",
      "Headline :  Large Indiana employers Eli Lilly and Cummins speak out about the state's new restrictive abortion law\n",
      "Time:  9 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/eli-lilly-says-indianas-abortion-law-will-lead-the-drugmaker-to-grow-in-other-states.html\n",
      "\n",
      "Headline :  Czech prince raises $300,000 in NFTs to restore castles and ancient artifacts\n",
      "Time:  12 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/27-year-old-bohemian-prince-raises-300000-in-nfts-to-preserve-and-share-castles-and-ancient-artifacts.html\n",
      "\n",
      "Headline :  President Joe Biden tests negative for Covid-19 after rebound case\n",
      "Time:  12 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/president-joe-biden-tests-negative-for-covid-19-after-rebound-case.html\n",
      "\n",
      "Headline :  Fed Governor Bowman sees 'similarly sized' interest rate hikes ahead \n",
      "Time:  13 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/fed-governor-bowman-sees-similarly-sized-rate-hikes-ahead-after-three-quarter-point-moves.html\n",
      "\n",
      "Headline :  This 39-year-old makes $160K/month in passive income—a look at his typical day: 'I work 5 hours a week'\n",
      "Time:  14 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/this-39-year-old-makes-160000-month-in-passive-income-a-look-at-his-typical-day-i-work-5-hours-a-week.html\n",
      "\n",
      "Headline :  Most of Buffett’s portfolio is tied up in just 5 stocks. Here’s what they are\n",
      "Time:  15 Hours Ago\n",
      "Headline_URL : /pro/\n",
      "\n",
      "Headline :  5 tips for cutting down on credit card costs ahead of rising interest rates\n",
      "Time:  15 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/how-to-curb-credit-card-debt-now-before-interest-rates-rise-again.html\n",
      "\n",
      "Headline :  This 41-year-old left the U.S. for Bangkok and lives on $8,000 a month\n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/this-digital-nomad-left-the-us-for-bangkok-and-lives-on-8000-per-month.html\n",
      "\n",
      "Headline :  It's time to cash in on these attractive stocks, according to Goldman Sachs\n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : /pro/\n",
      "\n",
      "Headline :  Here's why getting fired from a job you hate can still be upsetting \n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/therapist-getting-fired-from-a-toxic-job-can-still-be-upsetting.html\n",
      "\n",
      "Headline :  'Stressed out' STD clinics struggle with surge in monkeypox patients\n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/monkeypox-std-clinics-struggle-with-surge-in-patients-amid-outbreak-.html\n",
      "\n",
      "Headline :  Want to build generational wealth? Avoid these 7 U.S. cities\n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/building-generational-wealth-avoid-these-cities-in-texas-california.html\n",
      "\n",
      "Headline :  A.I.-powered drug hunters are nearing a pivotal stage in their development \n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : /pro/\n",
      "\n",
      "Headline :  The 2022 stock market doesn't have to repeat — it only has to rhyme\n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : /pro/\n",
      "\n",
      "Headline :  Berkshire reports operating earnings surge, but posts big investment loss \n",
      "Time:  16 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/berkshire-hathaway-brk-earnings-q2-2022.html\n",
      "\n",
      "Headline :  Why the best states for business may be the worst for workers\n",
      "Time:  17 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/state-worker-protections.html\n",
      "\n",
      "Headline :  Higher prices, skimpier portions and apps — how fast-food chains are changing value deals\n",
      "Time:  17 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/higher-prices-skimpier-portions-apps-fast-food-deals-are-changing.html\n",
      "\n",
      "Headline :  What to know before 'unretiring' if you're on Social Security\n",
      "Time:  17 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/social-security-retirement-benefits-what-to-know-if-you-unretire.html\n",
      "\n",
      "Headline :  Netflix is expanding its push into video games, but few subscribers are playing\n",
      "Time:  17 Hours Ago\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/netflixs-video-game-push-sees-few-subscribers-playing-along.html\n",
      "\n",
      "Headline :  There are 'more intelligent ways' for U.S. to support Taiwan: ex-Singapore diplomat\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/06/speaker-pelosis-taiwan-visit-made-things-worse-ex-singapore-diplomat.html\n",
      "\n",
      "Headline :  California DMV accuses Tesla of deceptive marketing around Autopilot, FSD\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/california-dmv-says-tesla-fsd-autopilot-marketing-deceptive.html\n",
      "\n",
      "Headline :  Gig economy stocks pop after companies show strong demand for their services\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/uber-and-lyft-stocks-had-their-best-week-ever.html\n",
      "\n",
      "Headline :  Twitter-Musk drama escalates in legal filings as both sides claim bad behavior\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/twitter-musk-drama-escalates-in-legal-filings-claiming-bad-behavior.html\n",
      "\n",
      "Headline :  CNBC in 5 minutes: Here are all the stock calls made on CNBC today\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : /pro/\n",
      "\n",
      "Headline :  More Americans worked part-time last month as recession fears linger\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/july-jobs-report-shows-more-americans-working-part-time.html\n",
      "\n",
      "Headline :  Big Oil is giving back tons of cash — and other things we've learned from earnings\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : /investingclub/\n",
      "\n",
      "Headline :  Investing Club: The week in review, the week ahead — August 5, 2022\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : /investingclub/\n",
      "\n",
      "Headline :  Schumer says Sinema left 'no choice' but to cut carried interest from key bill\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/sinema-made-schumer-cut-carried-interest-loophole-from-reconciliation-bill.html\n",
      "\n",
      "Headline :  Danger ahead: The U.S. economy has yet to face its biggest recession challenge\n",
      "Time:  August 5, 2022\n",
      "Headline_URL : https://www.cnbc.com/2022/08/05/danger-ahead-the-us-economy-has-yet-to-face-its-biggest-recession-challenge.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.cnbc.com/world/\"\n",
    "response=requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "\n",
    "News=soup.find_all(\"li\",class_=\"LatestNews-item\")\n",
    "Headlines=soup.find(\"div\",class_=\"LatestNews-container\")\n",
    "\n",
    "for Headlines in News:\n",
    "    Headline = Headlines.find(class_=\"LatestNews-headline\").text\n",
    "    Time=Headlines.find('time',class_=\"LatestNews-timestamp\").text\n",
    "    \n",
    "    Headline_URL=Headlines.find(\"div\",class_=\"LatestNews-headlineWrapper\").a['href']\n",
    "    print(\"Headline : \",Headline )\n",
    "    print(\"Time: \",Time)\n",
    "   \n",
    "    print(\"Headline_URL :\", Headline_URL)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987349d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b01afcd5",
   "metadata": {},
   "source": [
    "9)Write a python program to scrape mentioned details from dineout.co.in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361ade65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant_name :  Rang Marathi\n",
      "Location:  Sudama Nagar, South Indore\n",
      "Rating:  3.3\n",
      "Link:  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/5/i/u/p56660-15569810115ccda513d24e1.jpg?tr=tr:n-large\n",
      "Restaurant_name :  2o2 Di Restro Cafe\n",
      "Location:  Rajendra Nagar, South Indore\n",
      "Rating:  3.6\n",
      "Link:  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/8/b/n/p86126-161848824360782bb387366.jpg?tr=tr:n-large\n",
      "Restaurant_name :  Naivedyam Restaurant\n",
      "Location:  Rajendra Nagar, South Indore\n",
      "Rating:  2.8\n",
      "Link:  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/7/q/b/p71059-15744966435dd8e983a8d1c.jpg?tr=tr:n-large\n",
      "Restaurant_name :  Oh! Indore - Flavours Of Jail - Pure Veg Restaurant\n",
      "Location:  Bhanwar Kuan, South Indore\n",
      "Rating:  4.4\n",
      "Link:  https://im1.dineout.co.in/images/uploads/restaurant/sharpen/1/k/s/p103937-164543214262134d4ef3b13.jpg?tr=tr:n-large\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.dineout.co.in/indore?loc=Indore\"\n",
    "response=requests.get(url)\n",
    "soup = BeautifulSoup(response.content)\n",
    "#print(soup)\n",
    "Restaurants=soup.find_all(\"div\",class_=\"_3ZUwv\")\n",
    "Restaurant=soup.find(\"div\",class_=\"_3ZUwv\")\n",
    "\n",
    "#print(Restaurants)\n",
    "#print(Restaurant)\n",
    "for Restaurant in Restaurants:\n",
    "    \n",
    "\n",
    "    Restaurant_name = Restaurant.find(\"h4\",class_=\"_1jbOb\").text\n",
    "    Location=Restaurant.find('p',class_=\"_1jbOb\").text\n",
    "    Rating=Restaurant.find('div',class_=\"kGUdK _1oTbl\").text\n",
    "    Link=Restaurant.find('div',class_=\"_2DVRC\").img['data-src']\n",
    "    \n",
    "    \n",
    "    print(\"Restaurant_name : \",Restaurant_name )\n",
    "    print(\"Location: \",Location)\n",
    "    print(\"Rating: \",Rating)\n",
    "    print(\"Link: \",Link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a306385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9628b798",
   "metadata": {},
   "source": [
    "10)Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c1d4a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-index h5-median\n",
       "0     1.                                             Nature      444       667\n",
       "1     2.                The New England Journal of Medicine      432       780\n",
       "2     3.                                            Science      401       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "4     5.                                         The Lancet      354       635\n",
       "..   ...                                                ...      ...       ...\n",
       "95   96.                       Journal of Business Research      145       233\n",
       "96   97.                                   Molecular Cancer      145       209\n",
       "97   98.                                            Sensors      145       201\n",
       "98   99.                              Nature Climate Change      144       228\n",
       "99  100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://scholar.google.com/citations?view_op=top_venues\"\n",
    "response=requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "#print(soup)\n",
    "myTable=soup.find('table',{'class':'gsc_mp_table'})\n",
    "myTable\n",
    "row_headers=[]\n",
    "for x in myTable.find_all('tr'):\n",
    "    for y in x.find_all('th'):\n",
    "        row_headers.append(y.text)\n",
    "row_headers\n",
    "tableValues=[]\n",
    "for x in myTable.find_all('tr')[1:]:\n",
    "    td_tags=x.find_all('td')\n",
    "    td_val = [y.text for y in td_tags]\n",
    "    tableValues.append(td_val)\n",
    "tableValues\n",
    "df=pd.DataFrame(tableValues,columns=['Rank','Publication','h5-index','h5-median'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c88930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ec02f6",
   "metadata": {},
   "source": [
    "2)Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a7bbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>year_of_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.234551547968831</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.156467447442855</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.986868143620159</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>8.984643521434146</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>8.949004125379105</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>8.255570173060574</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.254750227826436</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.252988061630097</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.247278174523581</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>8.246615972427463</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           movie_name             rating year_of_release\n",
       "0            The Shawshank Redemption  9.234551547968831            1994\n",
       "1                       The Godfather  9.156467447442855            1972\n",
       "2                     The Dark Knight  8.986868143620159            2008\n",
       "3               The Godfather Part II  8.984643521434146            1974\n",
       "4                        12 Angry Men  8.949004125379105            1957\n",
       "..                                ...                ...             ...\n",
       "95                             Jagten  8.255570173060574            2012\n",
       "96  M - Eine Stadt sucht einen Mörder  8.254750227826436            1931\n",
       "97                 North by Northwest  8.252988061630097            1959\n",
       "98                            Vertigo  8.247278174523581            1958\n",
       "99                       Idi i smotri  8.246615972427463            1985\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "list = []\n",
    "for index in range(0, 100):\n",
    "\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_name = movie[len(str(index))+1:-7]\n",
    "    year_of_release= re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    \n",
    "    data = {\n",
    "            \"movie_name\": movie_name,\n",
    "            \"rating\":ratings[index],\n",
    "            \"year_of_release\": year_of_release,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "\n",
    "for movie in list:\n",
    "    ( movie['movie_name'], '(' +movie['year_of_release'] , movie['rating'])\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('imdb_top_250_movies.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53d018",
   "metadata": {},
   "source": [
    "3)Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aba7c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effect</td>\n",
       "      <td>8.48639162102755</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.398118709207884</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.390050028931475</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.384914687854318</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.384837780001678</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rang De Basanti</td>\n",
       "      <td>8.01406400819</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Baasha</td>\n",
       "      <td>8.01216548521176</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.007769874241347</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.007255540840514</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.005622665784061</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       movie_title             rating  year\n",
       "place                                                      \n",
       "1       Rocketry: The Nambi Effect   8.48639162102755  2022\n",
       "2                       Anbe Sivam  8.398118709207884  2003\n",
       "3                          Golmaal  8.390050028931475  1979\n",
       "4                         Jai Bhim  8.384914687854318  2021\n",
       "5                          Nayakan  8.384837780001678  1987\n",
       "...                            ...                ...   ...\n",
       "96                 Rang De Basanti      8.01406400819  2006\n",
       "97                          Baasha   8.01216548521176  1995\n",
       "98     Baahubali 2: The Conclusion  8.007769874241347  2017\n",
       "99                          Masaan  8.007255540840514  2015\n",
       "10                         Kahaani  8.005622665784061  2012\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Downloading imdb top 250 movie's data\n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')]\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    "\n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, 100):\n",
    "    \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"place\": place,\n",
    "            \"movie_title\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "\n",
    "for movie in list:\n",
    "        (movie['place'], '-', movie['movie_title'], '('+movie['year'] +\n",
    "        ') -',movie['rating'])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df.to_csv('imdb_top_250_movies.csv')\n",
    "df.set_index('place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31a2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4c69c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a5327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4cf73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a5fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed4680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed560d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd863b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e707b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbf4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
